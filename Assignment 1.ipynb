{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f006015c",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:30px;\">Do not use any libraries other than those that exist in this notebook.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a182e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 제시된 라이브러리 이외에 다른 외부 라이브러리를 활용해서는 안됨 \n",
    "# 함수는 각자 필요에 따라서 만들면 됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d716e",
   "metadata": {},
   "source": [
    "# Problem 1: US President height\n",
    "\n",
    "**Problem**: The dataset provided below contains the heights of U.S. Presidents. Using this data, answer the following questions.\n",
    "\n",
    "1. How many U.S. Presidents are in the dataset?\n",
    "2. What is the mean height of the U.S. Presidents?\n",
    "3. What is the median height of the U.S. Presidents?\n",
    "4. What is the variance of the heights of the U.S. Presidents?\n",
    "5. Who is the tallest U.S. President?\n",
    "6. Who is the shortest U.S. president (if there are two presidents, in alphabetical order)?\n",
    "7. What is the mean height of the top 10 tallest U.S. Presidents?\n",
    "8. What is the mean height of the bottom 10 shortest U.S. Presidents?\n",
    "9. What is the 25th percentile of the heights of the U.S. Presidents?\n",
    "10. What is the mean height of U.S. Presidents whose first name is James?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afc7e9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th>name</th>\n",
       "      <th>height(cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Thomas Jefferson</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>James Madison</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>James Monroe</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order               name  height(cm)\n",
       "0      1  George Washington         189\n",
       "1      2         John Adams         170\n",
       "2      3   Thomas Jefferson         189\n",
       "3      4      James Madison         163\n",
       "4      5       James Monroe         183"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('Data/president_heights.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceb4e259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Number of U.S. Presidents\n",
    "num_presidents = None\n",
    "\n",
    "# 2. Mean height of the presidents\n",
    "mean_height = None\n",
    "\n",
    "# 3. Median height of the presidents\n",
    "median_height = None\n",
    "\n",
    "# 4. Variance of the presidents' heights\n",
    "variance_height = None\n",
    "\n",
    "# 5. Name of the tallest president\n",
    "tallest_president = None\n",
    "\n",
    "# 6. Name of the shortest president\n",
    "shortest_president = None\n",
    "\n",
    "# 7. Mean height of the top 10 tallest presidents\n",
    "top_10_mean_height = None\n",
    "\n",
    "# 8. Mean height of the bottom 10 shortest presidents\n",
    "bottom_10_mean_height = None\n",
    "\n",
    "# 9. 25th percentile of the presidents' heights\n",
    "percentile_25 = None\n",
    "\n",
    "# 10. Mean height of presidents whose first name is James\n",
    "james_mean_height = None\n",
    "\n",
    "# Problem 1 answers\n",
    "Problem_1_answers = [ num_presidents, mean_height, median_height, variance_height, tallest_president, shortest_president, top_10_mean_height, bottom_10_mean_height, percentile_25, james_mean_height ]\n",
    "Problem_1_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5602d75d",
   "metadata": {},
   "source": [
    "# Problem 2: Boston housing data\n",
    "\n",
    "The **`Boston`** dataset records **`medv`** (Median value of owner-occupied homes in \\$1000's) for \n",
    " neighborhoods around Boston. We will build a regression model to predict **`medv`** using \n",
    " predictors such as **`crim`** (per capita crime rate by town), **`zn`** (proportion of residential land zoned for lots over 25,000 sq.ft), **`indus`** (proportion of non-retail business acres per town), **`chas`** (Charles River dummy variable (1 if tract bounds river; 0 otherwise), **`nox`** (nitric oxides concentration (parts per 10 million)), **`rm`** (average number of rooms per dwelling), **`dis`** (weighted distances to five Boston employment centres), **`rad`** (index of accessibility to radial highways),\n",
    "**`tax`** (full-value property-tax rate per \\$10,000), **`ptratio`** (pupil-teacher ratio by town B - 1000$(Bk - 0.63)^2$ where Bk is the proportion of blacks by town), **`lstat`** (percent of households with low socioeconomic status)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe57b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "   lstat  medv  \n",
       "0   4.98  24.0  \n",
       "1   9.14  21.6  \n",
       "2   4.03  34.7  \n",
       "3   2.94  33.4  \n",
       "4   5.33  36.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Data/Boston.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff48a8f",
   "metadata": {},
   "source": [
    "1. **Calculate the Interquartile Range (IQR)** for the **`medv`** column.\n",
    "   \n",
    "2. **Calculate the percentage of values smaller than Q1 - 1.5*IQR** for the **`medv`** column (Round the percentage to the nearest integer).\n",
    "\n",
    "3. **Compute the Pearson correlation coefficient** between **`medv`** and **`lstat`** .\n",
    "\n",
    "4. **Calculate the skewness** of the **`medv`** column.\n",
    "\n",
    "5. **Perform an OLS regression** to predict **`medv`** using **`lstat`** as the predictor (without an intercept). Report the coefficient value.\n",
    "\n",
    "6. **Perform an OLS regression** to predict **`medv`** using **`lstat`**, **`age`**, and **`nox`** as the predictors (with an intercept). Report the **adjusted R²** value.\n",
    "\n",
    "7. **Construct the variance-covariance matrix** of the coefficients from the model in question 6, and calculate the sum of the diagonal elements of the matrix.\n",
    "\n",
    "8. **Calculate the t-statistic** for the coefficient of **`nox`** in the model from question 6.\n",
    "\n",
    "9. **Compute the sum of the residuals** from the model in question 6.\n",
    "\n",
    "10. **Calculate the sum of the fitted `y` values** from the model in question 6.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91a40783",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "# 1. Interquartile Range (IQR) for the medv column\n",
    "IQR = None\n",
    "\n",
    "\n",
    "# 2. Calculate the percentage of values smaller than Q1 - 1.5*IQR for the medv column\n",
    "percentage_below_rounded = None\n",
    "\n",
    "# 3. Pearson correlation coefficient between medv and lstat\n",
    "pearson_corr = None\n",
    "\n",
    "# 4. Skewness of the medv column\n",
    "medv_skewness = None\n",
    "\n",
    "# 5. OLS regression for medv as y and lstat as x (without intercept)\n",
    "coef_lstat_only = None\n",
    "\n",
    "# 6. OLS regression with medv as y and lstat, age, nox as x (with intercept)\n",
    "beta_combined = None\n",
    "\n",
    "# Calculating adjusted R-squared in question 6\n",
    "adjusted_R2 = None\n",
    "\n",
    "# 7. Variance-covariance matrix and sum of diagonal elements\n",
    "sum_diag_elements = None\n",
    "\n",
    "# 8. t-statistic for the coefficient of nox\n",
    "t_stat_nox = None\n",
    "\n",
    "# 9. Sum of the residuals from the model in question 6\n",
    "sum_residuals = None\n",
    "\n",
    "# 10. Sum of the fitted y values from the model in question 6\n",
    "sum_fitted_y = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0abd502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Problem 2 answers\n",
    "Problem_2_answers = [\n",
    "    IQR,  # 1. IQR\n",
    "    percentage_below_rounded,  # 2. Percentage below Q1 - 1.5*IQR\n",
    "    pearson_corr,  # 3. Pearson correlation (medv, lstat)\n",
    "    medv_skewness,  # 4. Skewness of medv\n",
    "    coef_lstat_only,  # 5. OLS coefficient (medv ~ lstat)\n",
    "    adjusted_R2,  # 6. Adjusted R2 (medv ~ lstat, age, nox)\n",
    "    sum_diag_elements,  # 7. Sum of diagonal elements (variance-covariance matrix)\n",
    "    t_stat_nox,  # 8. t-statistic for nox\n",
    "    sum_residuals,  # 9. Sum of residuals\n",
    "    sum_fitted_y  # 10. Sum of fitted y values\n",
    "]\n",
    "Problem_2_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ac4863",
   "metadata": {},
   "source": [
    "# Problem 3: Auto\n",
    "\n",
    "Auto Data is consisted of Gas mileage, horsepower, and other information for 392 vehicles. The dataframe with 392 observations on the following 9 variables.**`mpg`** (miles per gallon), **`cylinders`**(Number of cylinders between 4 and 8), **`displacement`**(Engine displacement (cu. inches)), **`horsepower`**(Engine horsepower), **`weight`**(Vehicle weight (lbs.)), **`acceleration`**(Time to accelerate from 0 to 60 mph (sec.)), **`year`**(Model year (modulo 100)), **`origin`**(Origin of car (1. American, 2. European, 3. Japanese)), **`name`** (Vehicle name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2f5401b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mpg', 'cylinders', 'displacement', 'horsepower', 'weight',\n",
       "       'acceleration', 'year', 'origin', 'name'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Data/Auto.csv')\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af1f68",
   "metadata": {},
   "source": [
    "For **ridge regression**, the objective function adds a penalty term to the RSS, specifically:\n",
    "\n",
    "$$\n",
    "\\text{Ridge Objective} = \\text{RSS} + \\lambda \\sum_{j=1}^{p} \\beta_j^2\n",
    "$$\n",
    "\n",
    "This leads to a modified **normal equation** for ridge regression:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}^R = (X^TX + \\lambda I)^{-1}X^Ty\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $I$ is the **identity matrix** of size $p \\times p$.\n",
    "- $\\lambda$ is the **tuning parameter** that controls the amount of shrinkage applied to the coefficients.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "1. Split the dataset into **train data** (where the index is even) and **test data** (where the index is odd). Calculate the mean of **mpg** in the train data.\n",
    "   \n",
    "2. In the **train data**, set **y** as **mpg**, and **X** as a NumPy array consisting of all columns except **mpg**, **name**, and **year**. What is the value of **X.shape[1]**?\n",
    "\n",
    "3. Standardize **X** using z-standardization, and find the maximum value in the **weight** column after standardization.\n",
    "\n",
    "4. Perform Ridge regression using **y** and **X**, with **lambda = 0**. What is the coefficient for the **weight** column?\n",
    "\n",
    "5. Perform Ridge regression using **y** and **X**, with **lambda = 50**. What is the coefficient for the **weight** column?\n",
    "\n",
    "6. In the model from question 5, what is the coefficient for the **cylinders** column?\n",
    "\n",
    "7. In the model from question 5, what is the coefficient for the **displacement** column?\n",
    "\n",
    "8. In the model from question 5, what is the coefficient for the **horsepower** column?\n",
    "\n",
    "9. In the model from question 5, what is the coefficient for the **acceleration** column?\n",
    "\n",
    "10. Using the Ridge regression to **test data** from question 1 (without standardization), calculate the **LOOCV** (Leave-One-Out Cross Validation) MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d028fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 1: Split data into train (even index) and test (odd index)\n",
    "# Calculate mean of 'mpg' in train data\n",
    "\n",
    "train_data = None\n",
    "test_data = None\n",
    "train_mpg_mean = None\n",
    "\n",
    "# 2: Prepare X and y for train data (excluding mpg, name, year)\n",
    "# Get the number of features (X.shape[1])\n",
    "\n",
    "X_train = None\n",
    "y_train = None\n",
    "n_features = None\n",
    "\n",
    "# 3: Standardize X_train and find the max value in the weight column after standardization\n",
    "def standardize(X):\n",
    "    mean_X = np.mean(X, axis=0)\n",
    "    std_X = np.std(X, axis=0, ddof=1)\n",
    "    return (X - mean_X) / std_X\n",
    "\n",
    "max_weight_standardized = None\n",
    "\n",
    "# 4 & 5: Ridge regression function and calculation\n",
    "def ridge_regression(X, y, lam):\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    return beta_ridge\n",
    "\n",
    "beta_ridge_lambda_0 = None\n",
    "beta_ridge_lambda_50 = None\n",
    "\n",
    "# 6–9: Coefficients for specific features based on Question 5 (lambda=50 model)\n",
    "cylinder_coef_lambda_50 = None\n",
    "displacement_coef_lambda_50 = None\n",
    "horsepower_coef_lambda_50 = None\n",
    "acceleration_coef_lambda_50 = None\n",
    "\n",
    "# 10: LOOCV MSE calculation for test data\n",
    "#class LOOCV:\n",
    "    #return None\n",
    "\n",
    "mse_loocv = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "561f7db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Problem_3_answers = [\n",
    "    train_mpg_mean,  # 1. Train mpg mean\n",
    "    n_features,  # 2. X_train.shape[1]\n",
    "    max_weight_standardized,  # 3. Max value in standardized weight\n",
    "    beta_ridge_lambda_0,  # 4. Weight coefficient (lambda=0)\n",
    "    beta_ridge_lambda_50,  # 5. Weight coefficient (lambda=50)\n",
    "    cylinder_coef_lambda_50,  # 6. Cylinders coefficient (lambda=50)\n",
    "    displacement_coef_lambda_50,  # 7. Displacement coefficient (lambda=50)\n",
    "    horsepower_coef_lambda_50,  # 8. Horsepower coefficient (lambda=50)\n",
    "    acceleration_coef_lambda_50,  # 9. Acceleration coefficient (lambda=50)\n",
    "    mse_loocv  # 10. LOOCV MSE\n",
    "]\n",
    "\n",
    "Problem_3_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6323e8",
   "metadata": {},
   "source": [
    "# Problem 4: BBC data\n",
    "\n",
    "The data is consisted of 5 categories and 2,225 texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56095a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tech</td>\n",
       "      <td>games maker fights for survival one of britain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tech</td>\n",
       "      <td>security warning over  fbi virus  the us feder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tech</td>\n",
       "      <td>halo 2 heralds traffic explosion the growing p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tech</td>\n",
       "      <td>mobile audio enters new dimension as mobile ph...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                               text\n",
       "0     tech  tv future in the hands of viewers with home th...\n",
       "1     tech  games maker fights for survival one of britain...\n",
       "2     tech  security warning over  fbi virus  the us feder...\n",
       "3     tech  halo 2 heralds traffic explosion the growing p...\n",
       "4     tech  mobile audio enters new dimension as mobile ph..."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Data/bbc.csv')\n",
    "data = data[data['category']=='tech']\n",
    "data.reset_index(inplace=True,drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d376f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def tokenizer(corpus) :\n",
    "    processed_corpus = []\n",
    "    for sentence in corpus:\n",
    "        # Convert to lowercase\n",
    "        sentence = sentence.lower()\n",
    "        \n",
    "        # Remove punctuation and non-alphabetic characters\n",
    "        sentence = re.sub(r'[^a-z\\s]', '', sentence)\n",
    "        \n",
    "        # Tokenize (split the sentence into words)\n",
    "        words = sentence.split()\n",
    "        \n",
    "        processed_corpus.append([word for word in words if len(word)>=3])\n",
    "    \n",
    "    return processed_corpus\n",
    "\n",
    "corpus = data['text']\n",
    "tokenized_doc_pre = tokenizer(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "279b7f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Count word frequencies\n",
    "word_freq = defaultdict(int)\n",
    "for sentence in tokenized_doc_pre:\n",
    "    for word in sentence:\n",
    "        word_freq[word] += 1\n",
    "        \n",
    "# Filter the vocabulary to include only words that appear more than 50 times\n",
    "min_freq = 50\n",
    "vocabulary = sorted([word for word, freq in word_freq.items() if freq >= min_freq])\n",
    "\n",
    "tokenized_doc = []\n",
    "for doc in tokenized_doc_pre:\n",
    "    temp_list = [] \n",
    "    for word in doc:\n",
    "        if word in vocabulary:\n",
    "            temp_list.append(word)\n",
    "    tokenized_doc.append(temp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51399116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487, 401)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary), len(tokenized_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a7f96",
   "metadata": {},
   "source": [
    "1. Using **vocabulary** and **tokenized_doc**, construct a **Document-Term Matrix (DTM)**. What is the token with the highest term frequency in the 5th document?\n",
    "   \n",
    "2. In the first document, identify the token with the **lowest tf-idf value**.\n",
    "\n",
    "3. Sort the columns of the DTM by the document frequency (df) in **descending order** and identify value of the first row and column.\n",
    "\n",
    "4. Transpose the **sorted DTM in Q3** to construct a **Word-Document Matrix (X)**. What is the value of **X.shape[0]**?\n",
    "\n",
    "5. Perform **Singular Value Decomposition (SVD) on X in Q4**. How many singular values are in the **Singular Value Matrix**?\n",
    "\n",
    "6. **Using X in Q4** Perform Truncated SVD up to 3 dimensions and embed the documents into a **3-dimensional vector space**. What is the sum of the document embedding vector for the **third document (index 2)**?\n",
    "\n",
    "7. Similar to Q6, Derive word embedding vectors, calculate the sum of the word embedding vector corresponding to the token **\"apple\"**.\n",
    "\n",
    "8. Calculate the **cosine similarity** between the document embedding vector in Q6 (third document) and the word embedding vector from Q7 (token \"apple\").\n",
    "\n",
    "9. Using the document embedding vectors, calculate the **cosine similarity** between the **10th document (index 9)** and the **11th document (index 10)**.\n",
    "\n",
    "10. Using the DTM, calculate the **Jaccard similarity** between the **10th document** and the **11th document**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5439c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Data:\n",
    "documents = tokenized_doc\n",
    "\n",
    "# 1. Create DTM and find the most frequent token in the 5th document (index = 4)\n",
    "most_frequent_token = None\n",
    "\n",
    "# 2. Compute TF-IDF for the first document (index = 0) and find the token with the lowest TF-IDF\n",
    "lowest_tf_idf_token = None\n",
    "\n",
    "# 3. Sort DTM by document frequency in descending order, returen the first row and column element.\n",
    "dtm_sorted = None\n",
    "\n",
    "# 4. Transpose sorted DTM and find X.shape[0]\n",
    "#X = dtm_sorted.T\n",
    "X_shape_0 = None\n",
    "\n",
    "# 5. Perform SVD on X and calculate the number of non - zero singular value (over than threshold = 1e-10)\n",
    "threshold = 1e-10\n",
    "singular_value_count = None\n",
    "\n",
    "# 6. Find the embedding for the third document and calculate the sum\n",
    "sum_third_document_embedding = None\n",
    "\n",
    "# 7. Find the embedding for the word 'apple' and calculate its elements sum\n",
    "sum_apple_embedding = None\n",
    "\n",
    "# 8. Calculate cosine similarity between document 3's (index 2) embedding and the word 'apple'\n",
    "cosine_sim_doc_apple = None\n",
    "\n",
    "# 9. Calculate cosine similarity between the 10th and 11th document embeddings\n",
    "cosine_sim_doc_10_11 = None\n",
    "\n",
    "# 10. Calculate Jaccard similarity between the 10th and 11th documents using DTM\n",
    "jaccard_sim_doc_10_11 = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f12f46bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Problem_4_answers = [\n",
    "    most_frequent_token,  # 1. Token with the highest term frequency in the 5th document\n",
    "    lowest_tf_idf_token,  # 2. Token with the lowest TF-IDF value in the 1st document\n",
    "    dtm_sorted,  # 3. Value of the first row and column after sorting DTM by document frequency\n",
    "    X_shape_0,  # 4. X.shape[0] after transposing the sorted DTM\n",
    "    singular_value_count,  # 5. Number of singular values in the Singular Value Matrix\n",
    "    sum_third_document_embedding,  # 6. Sum of the document embedding vector for the third document\n",
    "    sum_apple_embedding,  # 7. Sum of the word embedding vector for the token \"apple\"\n",
    "    cosine_sim_doc_apple,  # 8. Cosine similarity between the third document and \"apple\"\n",
    "    cosine_sim_doc_10_11,  # 9. Cosine similarity between the 10th and 11th documents\n",
    "    jaccard_sim_doc_10_11  # 10. Jaccard similarity between the 10th and 11th documents using DTM\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278df59e",
   "metadata": {},
   "source": [
    "# Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fdb1640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([None, None, None, None, None, None, None, None, None, None],\n",
       " [None, None, None, None, None, None, None, None, None, None],\n",
       " [None, None, None, None, None, None, None, None, None, None],\n",
       " [None, None, None, None, None, None, None, None, None, None])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Problem_1_answers, Problem_2_answers, Problem_3_answers, Problem_4_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b2f7805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem 1</th>\n",
       "      <th>Problem 2</th>\n",
       "      <th>Problem 3</th>\n",
       "      <th>Problem 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Problem 1  Problem 2  Problem 3  Problem 4\n",
       "0        NaN        NaN        NaN        NaN\n",
       "1        NaN        NaN        NaN        NaN\n",
       "2        NaN        NaN        NaN        NaN\n",
       "3        NaN        NaN        NaN        NaN\n",
       "4        NaN        NaN        NaN        NaN\n",
       "5        NaN        NaN        NaN        NaN\n",
       "6        NaN        NaN        NaN        NaN\n",
       "7        NaN        NaN        NaN        NaN\n",
       "8        NaN        NaN        NaN        NaN\n",
       "9        NaN        NaN        NaN        NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 수치데이터인 경우는 소수점 3째자리에서 반올림한 값을 제출\n",
    "# 한국시간 24.10.28일 수업 시작 전까지 블랙보드의 Assignment 1에 ipynb 및 csv 파일 제출\n",
    "# 파일명은 모두 {학번_한글이름}으로 제출\n",
    "\n",
    "Answer_df = pd.DataFrame()\n",
    "Answer_df['Problem 1'] = Problem_1_answers\n",
    "Answer_df['Problem 2'] = Problem_2_answers\n",
    "Answer_df['Problem 3'] = Problem_3_answers\n",
    "Answer_df['Problem 4'] = Problem_4_answers\n",
    "\n",
    "# Apply rounding to numeric columns (column-wise)\n",
    "Answer_df = Answer_df.apply(pd.to_numeric, errors='ignore').round(2)\n",
    "\n",
    "# Apply rounding to numeric rows (row-wise)\n",
    "Answer_df = Answer_df.apply(lambda x: pd.to_numeric(x, errors='ignore')).applymap(lambda x: round(x, 2) if isinstance(x, (int, float)) else x)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "Answer_df.to_csv('202036201_정다운.csv', index=False)\n",
    "Answer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87f78a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문의 사항은 jdwoon0523@gmail.com으로 부탁드립니다. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
