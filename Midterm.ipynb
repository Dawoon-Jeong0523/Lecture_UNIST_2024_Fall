{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f006015c",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-size:30px;\">Do not use any libraries other than those that exist in this notebook.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6d716e",
   "metadata": {},
   "source": [
    "# Problem 1: US President height\n",
    "\n",
    "**Problem**: The dataset provided below contains the heights of U.S. Presidents. Using this data, answer the following questions.\n",
    "\n",
    "1. What is the mean height of U.S. Presidents?\n",
    "2. Calculate the integer value closest to the mean height of U.S. Presidents, and how many presidents have that exact height?\n",
    "3. What is the median height of U.S. Presidents?\n",
    "4. What is the standard deviation of the heights of U.S. Presidents?\n",
    "5. What is the tallest height of U.S. Presidents?\n",
    "6. What is the shortest height of U.S. Presidents?\n",
    "7. What is the mean height of U.S. Presidents ranked 11th to 20th in height?\n",
    "8. What is the 75th percentile of U.S. Presidents' heights?\n",
    "9. How many U.S. Presidents have heights greater than or equal to the 75th percentile?\n",
    "10. How many distinct last names are there among U.S. Presidents?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "afc7e9a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order</th>\n",
       "      <th>name</th>\n",
       "      <th>height(cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>George Washington</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Thomas Jefferson</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>James Madison</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>James Monroe</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order               name  height(cm)\n",
       "0      1  George Washington         189\n",
       "1      2         John Adams         170\n",
       "2      3   Thomas Jefferson         189\n",
       "3      4      James Madison         163\n",
       "4      5       James Monroe         183"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('Data/president_heights.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ceb4e259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Code to answer the new set of questions based on the president heights dataset\n",
    "\n",
    "# 1. Mean height of U.S. Presidents\n",
    "mean_height = None\n",
    "\n",
    "# 2. Calculate the integer value closest to the mean height of U.S. Presidents and how many presidents have that exact height\n",
    "num_presidents_with_closest_mean_height = None\n",
    "\n",
    "# 3. Median height of U.S. Presidents\n",
    "median_height = None\n",
    "\n",
    "# 4. Standard deviation of U.S. Presidents' heights\n",
    "stddev_height = None\n",
    "\n",
    "# 5. Tallest height of U.S. Presidents\n",
    "tallest_height = None\n",
    "\n",
    "# 6. Shortest height of U.S. Presidents\n",
    "shortest_height = None\n",
    "\n",
    "# 7. Mean height of U.S. Presidents ranked 11th to 20th in height\n",
    "top_11_to_20_mean_height = None\n",
    "\n",
    "# 8. 75th percentile of U.S. Presidents' heights\n",
    "percentile_75 = None\n",
    "\n",
    "# 9. Number of U.S. Presidents with heights greater than or equal to the 75th percentile\n",
    "num_presidents_above_75_percentile = None\n",
    "\n",
    "# 10. Number of distinct last names among U.S. Presidents\n",
    "num_distinct_last_names = None\n",
    "\n",
    "# Problem 1 answers\n",
    "Problem_1_answers = [\n",
    "    mean_height, \n",
    "    num_presidents_with_closest_mean_height, \n",
    "    median_height, \n",
    "    stddev_height, \n",
    "    tallest_height, \n",
    "    shortest_height, \n",
    "    top_11_to_20_mean_height, \n",
    "    percentile_75, \n",
    "    num_presidents_above_75_percentile, \n",
    "    num_distinct_last_names\n",
    "]\n",
    "Problem_1_answers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5602d75d",
   "metadata": {},
   "source": [
    "# Problem 2: Boston housing data\n",
    "\n",
    "The **`Boston`** dataset records **`medv`** (Median value of owner-occupied homes in \\$1000's) for \n",
    " neighborhoods around Boston. We will build a regression model to predict **`medv`** using \n",
    " predictors such as **`crim`** (per capita crime rate by town), **`zn`** (proportion of residential land zoned for lots over 25,000 sq.ft), **`indus`** (proportion of non-retail business acres per town), **`chas`** (Charles River dummy variable (1 if tract bounds river; 0 otherwise), **`nox`** (nitric oxides concentration (parts per 10 million)), **`rm`** (average number of rooms per dwelling), **`dis`** (weighted distances to five Boston employment centres), **`rad`** (index of accessibility to radial highways),\n",
    "**`tax`** (full-value property-tax rate per \\$10,000), **`ptratio`** (pupil-teacher ratio by town B - 1000$(Bk - 0.63)^2$ where Bk is the proportion of blacks by town), **`lstat`** (percent of households with low socioeconomic status)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1fe57b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "   lstat  medv  \n",
       "0   4.98  24.0  \n",
       "1   9.14  21.6  \n",
       "2   4.03  34.7  \n",
       "3   2.94  33.4  \n",
       "4   5.33  36.2  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Data/Boston.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff48a8f",
   "metadata": {},
   "source": [
    "1. What is the Interquartile Range (IQR) for the `medv` column?\n",
    "2. What percentage of values are greater than or equal to Q3 + 1.5*IQR in the `medv` column?\n",
    "3. What is the Pearson correlation coefficient between `medv` and `nox`?\n",
    "4. What is the skewness of the `age` column?\n",
    "5. Perform an OLS regression to predict `medv` using `lstat`, `age`, and `nox` as the predictors (with an intercept). Report the adjusted R² value.\n",
    "6. Construct the variance-covariance matrix of the coefficients from the model in question 5, and calculate the sum of the diagonal elements of the matrix.\n",
    "7. What is the R² value from the model in question 5?\n",
    "8. What is the t-statistic for the estimated coefficient of `nox` in the model from question 5?\n",
    "9. Calculate the 95% confidence interval for the estimated `nox` coefficient and find the sum of the upper and lower bounds.\n",
    "10. What is the intercept value of the OLS model from question 5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "91a40783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Interquartile Range (IQR) for the medv column\n",
    "IQR = None\n",
    "\n",
    "# 2. Percentage of values greater than or equal to Q1 + 1.5*IQR in the medv column\n",
    "percentage_above = None\n",
    "\n",
    "# 3. Pearson correlation coefficient between medv and nox\n",
    "pearson_corr_medv_nox = None\n",
    "\n",
    "# 4. Skewness of the age column\n",
    "age_skewness = None\n",
    "\n",
    "# 5. OLS regression to predict medv using lstat, age, and nox as predictors (with intercept) and Calculating Adjusted R-squared\n",
    "adjusted_R2 = None\n",
    "\n",
    "# 6. Variance-covariance matrix and sum of diagonal elements\n",
    "sum_diag_elements = None\n",
    "\n",
    "# 7. R² value from the model in question 5\n",
    "R2 = None\n",
    "\n",
    "# 8. t-statistic for the estimated coefficient of nox\n",
    "t_stat_nox = None\n",
    "\n",
    "# 9. Confidence interval for the estimated nox coefficient and sum of upper and lower bounds\n",
    "ci_sum_nox = None\n",
    "\n",
    "# 10. Intercept value of the OLS model from question 5\n",
    "intercept_value = None\n",
    "\n",
    "# Final answers in list format with comments indicating the original key names\n",
    "Problem_2_answers = [\n",
    "    IQR,  # 'IQR'\n",
    "    percentage_above,  # 'Percentage_above_Q3_plus_1.5IQR'\n",
    "    pearson_corr_medv_nox,  # 'Pearson_corr_medv_nox'\n",
    "    age_skewness,  # 'Age_skewness'\n",
    "    adjusted_R2,  # 'Adjusted_R2'\n",
    "    sum_diag_elements,  # 'Sum_of_diag_elements'\n",
    "    R2,  # 'R2_value'\n",
    "    t_stat_nox,  # 'T_stat_nox'\n",
    "    ci_sum_nox,  # 'Confidence_interval_sum_nox'\n",
    "    intercept_value  # 'Intercept_value'\n",
    "]\n",
    "\n",
    "Problem_2_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ac4863",
   "metadata": {},
   "source": [
    "# Problem 3: Auto\n",
    "\n",
    "Auto Data is consisted of Gas mileage, horsepower, and other information for 392 vehicles. The dataframe with 392 observations on the following 9 variables.**`mpg`** (miles per gallon), **`cylinders`**(Number of cylinders between 4 and 8), **`displacement`**(Engine displacement (cu. inches)), **`horsepower`**(Engine horsepower), **`weight`**(Vehicle weight (lbs.)), **`acceleration`**(Time to accelerate from 0 to 60 mph (sec.)), **`year`**(Model year (modulo 100)), **`origin`**(Origin of car (1. American, 2. European, 3. Japanese)), **`name`** (Vehicle name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2f5401b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>307.0</td>\n",
       "      <td>130</td>\n",
       "      <td>3504</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>chevrolet chevelle malibu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165</td>\n",
       "      <td>3693</td>\n",
       "      <td>11.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>buick skylark 320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3436</td>\n",
       "      <td>11.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>plymouth satellite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150</td>\n",
       "      <td>3433</td>\n",
       "      <td>12.0</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>amc rebel sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140</td>\n",
       "      <td>3449</td>\n",
       "      <td>10.5</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>ford torino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mpg  cylinders  displacement  horsepower  weight  acceleration  year  \\\n",
       "0  18.0          8         307.0         130    3504          12.0    70   \n",
       "1  15.0          8         350.0         165    3693          11.5    70   \n",
       "2  18.0          8         318.0         150    3436          11.0    70   \n",
       "3  16.0          8         304.0         150    3433          12.0    70   \n",
       "4  17.0          8         302.0         140    3449          10.5    70   \n",
       "\n",
       "   origin                       name  \n",
       "0       1  chevrolet chevelle malibu  \n",
       "1       1          buick skylark 320  \n",
       "2       1         plymouth satellite  \n",
       "3       1              amc rebel sst  \n",
       "4       1                ford torino  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Data/Auto.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cd7243",
   "metadata": {},
   "source": [
    "For **ridge regression**, the objective function adds a penalty term to the RSS, specifically:\n",
    "\n",
    "$$\n",
    "\\text{Ridge Objective} = \\text{RSS} + \\lambda \\sum_{j=1}^{p} \\beta_j^2\n",
    "$$\n",
    "\n",
    "This leads to a modified **normal equation** for ridge regression:\n",
    "\n",
    "$$\n",
    "\\hat{\\beta}^R = (X^TX + \\lambda I)^{-1}X^Ty\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $I$ is the **identity matrix** of size $p \\times p$.\n",
    "- $\\lambda$ is the **tuning parameter** that controls the amount of shrinkage applied to the coefficients.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "1. In the **name** column, the first word represents the manufacturer. Create a new column **firm** that contains the manufacturers of each car (ignore any spelling errors like \"toyouta\"; treat them as unique manufacturers).\n",
    "\n",
    "2. Split the data into **train** (where **firm** is not \"toyota\") and **test** (where **firm** is \"toyota\"). How many entries are in the train dataset?\n",
    "\n",
    "3. Standardize the **train** data. What is the minimum value in the **weight** column after standardization?\n",
    "\n",
    "4. Perform Ridge regression using the standardized **train** data with **lambda = 0**. What is the coefficient for the **weight** column? (ridge regression without intercept)\n",
    "\n",
    "5. Perform Ridge regression using the standardized **train** data with **lambda = 50**. What is the coefficient for the **weight** column? (ridge regression without intercept)\n",
    "\n",
    "6. In the model from question 5, what is the coefficient for the **cylinders** column?\n",
    "\n",
    "7. In the model from question 5, what is the coefficient for the **displacement** column?\n",
    "\n",
    "8. In the model from question 5, what is the coefficient for the **horsepower** column?\n",
    "\n",
    "9. In the model from question 5, what is the coefficient for the **acceleration** column?\n",
    "\n",
    "10. Using the Ridge regression with **lambda = 50** on the **test** data (without standardization), calculate the **LOOCV** (Leave-One-Out Cross Validation) MSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d028fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a 'firm' column by extracting the first word from the 'name' column\n",
    "number_firm = None\n",
    "\n",
    "# 2. Split the data into test (where firm is 'toyota') and train (all other firms) \n",
    "# Calculate the number of entries in the train dataset\n",
    "train_data_count = None\n",
    "\n",
    "# 3. Standardize the train data (excluding 'mpg', 'name', 'year', and 'firm')\n",
    "# Including cylinders, displacement, horsepower, weight, acceleration, origin\n",
    "# Find the minimum value in the weight column after standardization\n",
    "min_weight_standardized = None\n",
    "\n",
    "# Step 4–10: The remaining steps are the same as the original code provided\n",
    "# Ridge regression function and calculation\n",
    "# Ridge regression with lambda = 0 and lambda = 50\n",
    "# ridge regression without intercept\n",
    "beta_ridge_lambda_0 = None\n",
    "beta_ridge_lambda_50 = None\n",
    "\n",
    "# Coefficients for specific features based on lambda=50\n",
    "cylinder_coef_lambda_50 = None\n",
    "displacement_coef_lambda_50 = None\n",
    "horsepower_coef_lambda_50 = None\n",
    "acceleration_coef_lambda_50 = None\n",
    "\n",
    "# LOOCV MSE calculation for test data\n",
    "# Using LOOCV class to calculate MSE\n",
    "mse_loocv = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "561f7db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Problem_3_answers = [\n",
    "    number_firm,  # 1. Number of Manufacturers\n",
    "    train_data_count,  # 2. X_train.shape[1]\n",
    "    min_weight_standardized,  # 3. Min value in standardized weight\n",
    "    beta_ridge_lambda_0,  # 4. Weight coefficient (lambda=0)\n",
    "    beta_ridge_lambda_50,  # 5. Weight coefficient (lambda=50)\n",
    "    cylinder_coef_lambda_50,  # 6. Cylinders coefficient (lambda=50)\n",
    "    displacement_coef_lambda_50,  # 7. Displacement coefficient (lambda=50)\n",
    "    horsepower_coef_lambda_50,  # 8. Horsepower coefficient (lambda=50)\n",
    "    acceleration_coef_lambda_50,  # 9. Acceleration coefficient (lambda=50)\n",
    "    mse_loocv  # 10. LOOCV MSE\n",
    "]\n",
    "\n",
    "Problem_3_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6323e8",
   "metadata": {},
   "source": [
    "# Problem 4: BBC data\n",
    "\n",
    "The data is consisted of 5 categories and 2,225 texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "56095a06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tech</td>\n",
       "      <td>tv future in the hands of viewers with home th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tech</td>\n",
       "      <td>games maker fights for survival one of britain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tech</td>\n",
       "      <td>security warning over  fbi virus  the us feder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tech</td>\n",
       "      <td>halo 2 heralds traffic explosion the growing p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tech</td>\n",
       "      <td>mobile audio enters new dimension as mobile ph...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category                                               text\n",
       "0     tech  tv future in the hands of viewers with home th...\n",
       "1     tech  games maker fights for survival one of britain...\n",
       "2     tech  security warning over  fbi virus  the us feder...\n",
       "3     tech  halo 2 heralds traffic explosion the growing p...\n",
       "4     tech  mobile audio enters new dimension as mobile ph..."
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('Data/bbc.csv')\n",
    "data = data[data['category']=='tech']\n",
    "data.reset_index(inplace=True,drop=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4d376f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def tokenizer(corpus) :\n",
    "    processed_corpus = []\n",
    "    for sentence in corpus:\n",
    "        # Convert to lowercase\n",
    "        sentence = sentence.lower()\n",
    "        \n",
    "        # Remove punctuation and non-alphabetic characters\n",
    "        sentence = re.sub(r'[^a-z\\s]', '', sentence)\n",
    "        \n",
    "        # Tokenize (split the sentence into words)\n",
    "        words = sentence.split()\n",
    "        \n",
    "        processed_corpus.append([word for word in words if len(word)>=3])\n",
    "    \n",
    "    return processed_corpus\n",
    "\n",
    "corpus = data['text']\n",
    "tokenized_doc_pre = tokenizer(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "279b7f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Count word frequencies\n",
    "word_freq = defaultdict(int)\n",
    "for sentence in tokenized_doc_pre:\n",
    "    for word in sentence:\n",
    "        word_freq[word] += 1\n",
    "        \n",
    "# Filter the vocabulary to include only words that appear more than 50 times\n",
    "min_freq = 50\n",
    "vocabulary = sorted([word for word, freq in word_freq.items() if freq >= min_freq])\n",
    "\n",
    "# Vocabulary Index ************************************\n",
    "vocabulary_index = {i:word for i, word in enumerate(vocabulary)}\n",
    "\n",
    "tokenized_doc = []\n",
    "for doc in tokenized_doc_pre:\n",
    "    temp_list = [] \n",
    "    for word in doc:\n",
    "        if word in vocabulary:\n",
    "            temp_list.append(word)\n",
    "    tokenized_doc.append(temp_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a7f96",
   "metadata": {},
   "source": [
    "1. Using **vocabulary** and **tokenized_doc**, construct a **Document-Term Matrix (DTM)**. What is the token with the highest term frequency in the 5th document?\n",
    "\n",
    "2. In the first document, identify the token with the **lowest TF-IDF value**.\n",
    "\n",
    "3. Sort the columns of the DTM by the vocabulary index in given **vocabulary_index** and identify the value of the first row and column.\n",
    "\n",
    "4. Transpose the sorted DTM to construct a **Word-Document Matrix (X)**. What is the value of **X.shape[0]**?\n",
    "\n",
    "5. Perform **Singular Value Decomposition (SVD)** on X. How many singular values are in the **Singular Value Matrix**? (Singular values smaller than 1e-10 can be considered as 0.)\n",
    "\n",
    "6. Perform Truncated SVD up to 3 dimensions and embed the documents into a **3-dimensional vector space**. What is the sum of the document embedding vector for the **third document**?\n",
    "\n",
    "7. Using the word embedding vectors from step 4, calculate the sum of the word embedding vector corresponding to the token **\"apple\"**.\n",
    "\n",
    "8. **Find the word most similar to \"apple\"** using the word embedding vectors from step 7. Use **cosine similarity** to identify the closest word except 'apple'.\n",
    "\n",
    "9. **Find the document most similar to \"apple\"** using the word embedding vectors and document embedding vectors from step 6. Use **cosine similarity** to identify the document most similar to \"apple.\"\n",
    "\n",
    "10. Using the DTM, calculate the **Jaccard similarity** between the **10th document** and the **11th document**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5439c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "documents = tokenized_doc\n",
    "\n",
    "# 1. Create DTM and find the most frequent token in the 5th document (index = 4)\n",
    "most_frequent_token = None\n",
    "\n",
    "# 2. Compute TF-IDF for the first document (index = 0) and find the token with the lowest TF-IDF\n",
    "lowest_tf_idf_token = None\n",
    "\n",
    "# 3. Sort DTM by document frequency in descending order\n",
    "dtm_sorted_00 = None\n",
    "\n",
    "# 4. Transpose sorted DTM and find X.shape[0]\n",
    "X_shape_0 = None\n",
    "\n",
    "# 5. Perform SVD on X and Find Rank of Singular value Matrix\n",
    "threshold = 1e-10\n",
    "singular_value_count = None\n",
    "\n",
    "# 6. Find the embedding for the third document (index = 2) and calculate the sum\n",
    "sum_third_document_embedding = None\n",
    "\n",
    "# 7. Find the embedding for the word 'apple' and calculate its sum\n",
    "sum_apple_embedding = None\n",
    "\n",
    "# 8. Find the word (exclude apple) most similar to 'apple' using cosine similarity\n",
    "most_similar_word = None\n",
    "\n",
    "# 9. Find the document most similar to 'apple' using cosine similarity\n",
    "most_similar_document = None\n",
    "\n",
    "# 10. Calculate Jaccard similarity between the 10th (index = 9) and 11th documents (index = 10) using DTM\n",
    "jaccard_sim_doc_10_11 = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f12f46bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Problem_4_answers = [\n",
    "    most_frequent_token,  # 1. Token with the highest term frequency in the 5th document\n",
    "    lowest_tf_idf_token,  # 2. Token with the lowest TF-IDF value in the 1st document\n",
    "    dtm_sorted_00,  # 3. Value of the first row and column after sorting DTM by document frequency\n",
    "    X_shape_0,  # 4. X.shape[0] after transposing the sorted DTM\n",
    "    singular_value_count,  # 5. Number of singular values in the Singular Value Matrix\n",
    "    sum_third_document_embedding,  # 6. Sum of the document embedding vector for the third document\n",
    "    sum_apple_embedding,  # 7. Sum of the word embedding vector for the token \"apple\"\n",
    "    most_similar_word,  \n",
    "    most_similar_document,  \n",
    "    jaccard_sim_doc_10_11  # 10. Jaccard similarity between the 10th and 11th documents using DTM\n",
    "]\n",
    "Problem_4_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278df59e",
   "metadata": {},
   "source": [
    "# Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8fdb1640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([None, None, None, None, None, None, None, None, None, None],\n",
       " [None, None, None, None, None, None, None, None, None, None],\n",
       " [None, None, None, None, None, None, None, None, None, None],\n",
       " [None, None, None, None, None, None, None, None, None, None])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Problem_1_answers, Problem_2_answers, Problem_3_answers, Problem_4_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1871162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10, 10)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Problem_1_answers), len(Problem_2_answers), len(Problem_3_answers), len(Problem_4_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1b2f7805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Problem 1</th>\n",
       "      <th>Problem 2</th>\n",
       "      <th>Problem 3</th>\n",
       "      <th>Problem 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Problem 1  Problem 2  Problem 3  Problem 4\n",
       "0        NaN        NaN        NaN        NaN\n",
       "1        NaN        NaN        NaN        NaN\n",
       "2        NaN        NaN        NaN        NaN\n",
       "3        NaN        NaN        NaN        NaN\n",
       "4        NaN        NaN        NaN        NaN\n",
       "5        NaN        NaN        NaN        NaN\n",
       "6        NaN        NaN        NaN        NaN\n",
       "7        NaN        NaN        NaN        NaN\n",
       "8        NaN        NaN        NaN        NaN\n",
       "9        NaN        NaN        NaN        NaN"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 수치데이터인 경우는 소수점 3째자리에서 반올림한 값을 제출\n",
    "\n",
    "Answer_df = pd.DataFrame()\n",
    "Answer_df['Problem 1'] = Problem_1_answers\n",
    "Answer_df['Problem 2'] = Problem_2_answers\n",
    "Answer_df['Problem 3'] = Problem_3_answers\n",
    "Answer_df['Problem 4'] = Problem_4_answers\n",
    "\n",
    "# Apply rounding to numeric columns (column-wise)\n",
    "Answer_df = Answer_df.apply(pd.to_numeric, errors='ignore').round(2)\n",
    "\n",
    "# Apply rounding to numeric rows (row-wise)\n",
    "Answer_df = Answer_df.apply(lambda x: pd.to_numeric(x, errors='ignore')).applymap(lambda x: round(x, 2) if isinstance(x, (int, float)) else x)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "#Answer_df.to_csv('202036201_정다운.csv', index=False)\n",
    "Answer_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b87f78a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수고하셨습니다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb2bb47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
